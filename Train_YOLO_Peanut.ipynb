{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+c/zjJ6FAw6O9B26kEmmy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xo0ol/Train_YOLO_Peanut/blob/main/Train_YOLO_Peanut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NVIDIA GPU 가용 확인\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "m8AMH5VL3ra8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af042d4d-badf-42f3-99b8-a4844df4e5c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug 23 13:24:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YtGXF7fFylKY"
      },
      "outputs": [],
      "source": [
        "# roboflow 데이터를 unzip 폴더로 압축 해제\n",
        "!unzip -q /content/peanut_roboflow_data.zip -d /content/peanut_roboflow_data_unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
        "\n",
        "# TO DO: Improve robustness of train_val_split.py script so it can handle nested data folders, etc\n",
        "!python train_val_split.py --datapath=\"/content/peanut_roboflow_data_unzip\" --train_pct=0.9"
      ],
      "metadata": {
        "id": "Zh-X03waFae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493ab5c8-6d89-4b42-bfda-03787ea62297"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-23 13:27:24--  https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3203 (3.1K) [text/plain]\n",
            "Saving to: ‘/content/train_val_split.py’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/train_val_ 100%[===================>]   3.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-08-23 13:27:25 (52.1 MB/s) - ‘/content/train_val_split.py’ saved [3203/3203]\n",
            "\n",
            "Created folder at /content/data/train/images.\n",
            "Created folder at /content/data/train/labels.\n",
            "Created folder at /content/data/validation/images.\n",
            "Created folder at /content/data/validation/labels.\n",
            "Number of image files: 812\n",
            "Number of annotation files: 812\n",
            "Images moving to train: 730\n",
            "Images moving to validation: 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adlVvZrY0gKv",
        "outputId": "425b20b9-7769-428f-8f55-eed0376094a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.184-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.16-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.184-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.16-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.184 ultralytics-thop-2.0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# yaml 생성하기\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "# yaml 파일 생성 함수 만들기\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # classes.txt 파일에서 class name 가져오기\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # data dictionary 생성\n",
        "  data = {\n",
        "      'path': '/content/data',\n",
        "      'train': 'train/images',\n",
        "      'val': 'validation/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # yaml 파일 쓰기\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# 경로 설정하기\n",
        "path_to_classes_txt = '/content/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "\n",
        "# 함수 실행\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml"
      ],
      "metadata": {
        "id": "pGBrPAYWF8KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9028e076-9b00-451a-989e-f8a384502a56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created config file at /content/data.yaml\n",
            "\n",
            "File contents:\n",
            "\n",
            "path: /content/data\n",
            "train: train/images\n",
            "val: validation/images\n",
            "nc: 1\n",
            "names:\n",
            "- peanut\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 시작\n",
        "!yolo detect train data=/content/data.yaml model=yolo11s.pt epochs=50 imgsz=640 batch=8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECdUUnoE0k57",
        "outputId": "0523e170-8ea3-4126-989c-14e0a22df5de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.184 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% 755k/755k [00:00<00:00, 33.4MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "YOLO11s summary: 181 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
            "\n",
            "Transferred 493/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% 5.35M/5.35M [00:00<00:00, 105MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1670.0±598.3 MB/s, size: 54.8 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/train/labels... 730 images, 0 backgrounds, 0 corrupt: 100% 730/730 [00:00<00:00, 2546.61it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 597.6±432.8 MB/s, size: 63.5 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/validation/labels... 82 images, 0 backgrounds, 0 corrupt: 100% 82/82 [00:00<00:00, 1941.18it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/validation/labels.cache\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.21G      1.082       2.16      1.425          6        640: 100% 92/92 [00:34<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:07<00:00,  1.27s/it]\n",
            "                   all         82         82      0.674      0.854      0.827      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.63G      1.181      1.108      1.498          7        640: 100% 92/92 [00:15<00:00,  5.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.72it/s]\n",
            "                   all         82         82      0.515      0.402       0.37      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.65G      1.219      1.095      1.502          2        640: 100% 92/92 [00:15<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.01it/s]\n",
            "                   all         82         82      0.598      0.537      0.573      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.71G      1.185     0.9855      1.478          3        640: 100% 92/92 [00:16<00:00,  5.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.09it/s]\n",
            "                   all         82         82      0.707      0.646       0.68      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.74G      1.231     0.9603      1.518          4        640: 100% 92/92 [00:15<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.02it/s]\n",
            "                   all         82         82      0.806      0.862      0.928      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.79G      1.165      0.903      1.464          4        640: 100% 92/92 [00:15<00:00,  5.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.90it/s]\n",
            "                   all         82         82      0.888      0.866      0.955      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.82G      1.159     0.8725      1.444          5        640: 100% 92/92 [00:16<00:00,  5.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.04it/s]\n",
            "                   all         82         82      0.723      0.744      0.793      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.87G      1.018      0.801      1.344          4        640: 100% 92/92 [00:15<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.29it/s]\n",
            "                   all         82         82       0.92      0.732      0.865      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50       2.9G      1.032     0.7757      1.365          4        640: 100% 92/92 [00:15<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.17it/s]\n",
            "                   all         82         82      0.952      0.967      0.985      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.95G      1.018     0.7628      1.337          5        640: 100% 92/92 [00:16<00:00,  5.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.10it/s]\n",
            "                   all         82         82      0.948          1      0.992      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.97G     0.9759     0.7193      1.354          4        640: 100% 92/92 [00:15<00:00,  5.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.93it/s]\n",
            "                   all         82         82      0.974          1      0.993      0.741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      3.03G     0.9653     0.7115      1.326          3        640: 100% 92/92 [00:15<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  5.17it/s]\n",
            "                   all         82         82      0.877      0.963      0.944      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      3.05G     0.9379     0.6797      1.305          3        640: 100% 92/92 [00:16<00:00,  5.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.28it/s]\n",
            "                   all         82         82       0.78      0.793      0.793      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      3.11G     0.9166     0.6546      1.281          7        640: 100% 92/92 [00:15<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.67it/s]\n",
            "                   all         82         82       0.97          1      0.993      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      3.13G     0.8851     0.6437      1.261          2        640: 100% 92/92 [00:15<00:00,  5.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  5.83it/s]\n",
            "                   all         82         82      0.997          1      0.995      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      3.19G     0.9075     0.6292      1.274          8        640: 100% 92/92 [00:16<00:00,  5.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.26it/s]\n",
            "                   all         82         82      0.983          1      0.994      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      3.21G      0.882     0.6069      1.255          6        640: 100% 92/92 [00:15<00:00,  5.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.13it/s]\n",
            "                   all         82         82      0.981          1      0.995      0.829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      3.27G     0.8309     0.5823      1.232          6        640: 100% 92/92 [00:16<00:00,  5.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.18it/s]\n",
            "                   all         82         82          1      0.997      0.995       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      3.29G     0.8302     0.5801      1.231          5        640: 100% 92/92 [00:15<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.20it/s]\n",
            "                   all         82         82      0.998          1      0.995      0.827\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      3.35G      0.814     0.5726      1.201          2        640: 100% 92/92 [00:15<00:00,  5.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.09it/s]\n",
            "                   all         82         82      0.992          1      0.995      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      3.37G     0.8213     0.5666      1.215          5        640: 100% 92/92 [00:16<00:00,  5.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.26it/s]\n",
            "                   all         82         82          1          1      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      3.43G      0.807     0.5543      1.216          6        640: 100% 92/92 [00:15<00:00,  5.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.72it/s]\n",
            "                   all         82         82          1          1      0.995      0.833\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      3.45G     0.8186     0.5294      1.217          3        640: 100% 92/92 [00:15<00:00,  5.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.92it/s]\n",
            "                   all         82         82      0.993          1      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      3.51G     0.7679     0.5211      1.178          5        640: 100% 92/92 [00:16<00:00,  5.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.31it/s]\n",
            "                   all         82         82      0.987          1      0.995      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      3.53G     0.7685     0.5143      1.194          3        640: 100% 92/92 [00:15<00:00,  5.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.22it/s]\n",
            "                   all         82         82      0.994          1      0.995      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      3.59G     0.7471     0.4848      1.177          7        640: 100% 92/92 [00:15<00:00,  5.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.40it/s]\n",
            "                   all         82         82      0.953          1      0.995      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      3.61G     0.7576     0.5043      1.185          6        640: 100% 92/92 [00:16<00:00,  5.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.85it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      3.67G     0.7414     0.4895      1.174          6        640: 100% 92/92 [00:15<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.29it/s]\n",
            "                   all         82         82      0.986          1      0.995      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      3.69G      0.741     0.4795      1.161          5        640: 100% 92/92 [00:15<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.47it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      3.75G     0.6867     0.4513      1.128          5        640: 100% 92/92 [00:16<00:00,  5.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.63it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      3.77G     0.6992     0.4515      1.142          2        640: 100% 92/92 [00:15<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.26it/s]\n",
            "                   all         82         82      0.987          1      0.995      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      3.83G     0.6981     0.4702      1.158          5        640: 100% 92/92 [00:15<00:00,  5.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.01it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      4.01G     0.6782     0.4463      1.119          4        640: 100% 92/92 [00:16<00:00,  5.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.06it/s]\n",
            "                   all         82         82          1      0.997      0.995      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      4.07G     0.7025       0.44      1.157          3        640: 100% 92/92 [00:15<00:00,  5.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.97it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      4.09G     0.6622     0.4156      1.114          4        640: 100% 92/92 [00:15<00:00,  5.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.90it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      4.15G     0.6842     0.4248      1.129          5        640: 100% 92/92 [00:15<00:00,  5.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.03it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      4.17G     0.6729      0.428      1.117          5        640: 100% 92/92 [00:15<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  7.92it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.878\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      4.23G     0.6485     0.4131      1.118          5        640: 100% 92/92 [00:15<00:00,  5.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.42it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      4.25G     0.6638     0.4085      1.117          5        640: 100% 92/92 [00:16<00:00,  5.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.33it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      4.31G     0.6431     0.3926      1.099          2        640: 100% 92/92 [00:15<00:00,  5.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.50it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.895\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      4.33G     0.5129     0.2958      1.052          2        640: 100% 92/92 [00:15<00:00,  5.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.29it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      4.39G     0.5266     0.2874      1.033          2        640: 100% 92/92 [00:15<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.19it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      4.41G     0.5081     0.2763      1.041          2        640: 100% 92/92 [00:14<00:00,  6.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.13it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      4.47G     0.4965     0.2657      1.049          2        640: 100% 92/92 [00:15<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.38it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      4.49G     0.4913      0.267      1.034          2        640: 100% 92/92 [00:14<00:00,  6.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.36it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      4.54G     0.4684     0.2521      1.009          2        640: 100% 92/92 [00:16<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.52it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.891\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50       4.6G     0.4644     0.2473     0.9988          2        640: 100% 92/92 [00:14<00:00,  6.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.52it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.898\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      4.66G      0.462     0.2474     0.9959          2        640: 100% 92/92 [00:15<00:00,  6.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.45it/s]\n",
            "                   all         82         82      0.999          1      0.995       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50       4.7G     0.4517     0.2385      1.011          2        640: 100% 92/92 [00:15<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  6.15it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      4.78G     0.4386     0.2317     0.9934          2        640: 100% 92/92 [00:15<00:00,  6.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:00<00:00,  8.35it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.917\n",
            "\n",
            "50 epochs completed in 0.245 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 19.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 19.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.184 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:01<00:00,  3.23it/s]\n",
            "                   all         82         82      0.999          1      0.995      0.916\n",
            "Speed: 0.4ms preprocess, 6.5ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 객체 탐지\n",
        "\n",
        "# 영상 경로 지정\n",
        "video_path = r\"/content/peanut_test_video.mp4\"\n",
        "output_path = r\"/content/peanut_test_video_output.mp4\"\n",
        "\n",
        "# OpenCV로 영상 읽기\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise Exception(f\"영상 파일을 열 수 없습니다: {video_path}\")\n",
        "\n",
        "# 영상 정보 가져오기\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# 영상 저장용 VideoWriter\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "# 프레임 단위로 객체 탐지\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 객체 탐지\n",
        "    results = model.predict(frame)\n",
        "\n",
        "    # 탐지 결과 그리기\n",
        "    for result in results:\n",
        "        annotated_frame = result.plot()  # YOLOv8이 제공하는 plot()으로 바운딩 박스 그림\n",
        "\n",
        "    # 결과 영상 저장\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLdN7SONOewr",
        "outputId": "fdfddd89-a0d2-4f06-cb32-f22cbb3f39e8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.6ms\n",
            "Speed: 3.6ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.9ms\n",
            "Speed: 3.4ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.1ms\n",
            "Speed: 3.7ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 22.4ms\n",
            "Speed: 3.1ms preprocess, 22.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.9ms\n",
            "Speed: 3.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.5ms\n",
            "Speed: 3.7ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 18.1ms\n",
            "Speed: 3.2ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 24.0ms\n",
            "Speed: 5.1ms preprocess, 24.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 17.1ms\n",
            "Speed: 6.5ms preprocess, 17.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 17.6ms\n",
            "Speed: 3.2ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 21.2ms\n",
            "Speed: 5.2ms preprocess, 21.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 17.2ms\n",
            "Speed: 11.1ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.6ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.5ms\n",
            "Speed: 3.8ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.7ms\n",
            "Speed: 3.4ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 15.1ms\n",
            "Speed: 3.3ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 19.9ms\n",
            "Speed: 6.3ms preprocess, 19.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 17.3ms\n",
            "Speed: 3.2ms preprocess, 17.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.9ms\n",
            "Speed: 3.6ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 17.3ms\n",
            "Speed: 8.8ms preprocess, 17.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 14.8ms\n",
            "Speed: 3.3ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 17.5ms\n",
            "Speed: 4.6ms preprocess, 17.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 15.4ms\n",
            "Speed: 5.5ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 17.6ms\n",
            "Speed: 5.7ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.7ms\n",
            "Speed: 5.1ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 19.7ms\n",
            "Speed: 3.1ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 7.0ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 19.0ms\n",
            "Speed: 3.1ms preprocess, 19.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 20.9ms\n",
            "Speed: 8.7ms preprocess, 20.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 21.0ms\n",
            "Speed: 7.0ms preprocess, 21.0ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.9ms\n",
            "Speed: 3.3ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 2.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 2.8ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 2.8ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 18.3ms\n",
            "Speed: 3.0ms preprocess, 18.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.7ms\n",
            "Speed: 4.2ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.8ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.5ms\n",
            "Speed: 3.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 16.5ms\n",
            "Speed: 5.6ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.3ms\n",
            "Speed: 3.1ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 4.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.6ms\n",
            "Speed: 3.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.1ms\n",
            "Speed: 4.5ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 4.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.6ms\n",
            "Speed: 4.1ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.9ms\n",
            "Speed: 4.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 16.8ms\n",
            "Speed: 3.3ms preprocess, 16.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 4.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.7ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.5ms\n",
            "Speed: 3.3ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 24.5ms\n",
            "Speed: 4.6ms preprocess, 24.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.3ms\n",
            "Speed: 3.1ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.1ms\n",
            "Speed: 3.8ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.8ms\n",
            "Speed: 3.1ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 15.7ms\n",
            "Speed: 3.3ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.3ms\n",
            "Speed: 3.1ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.7ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.9ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.1ms\n",
            "Speed: 3.7ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.7ms\n",
            "Speed: 3.4ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.1ms\n",
            "Speed: 3.5ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 14.0ms\n",
            "Speed: 4.0ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.7ms\n",
            "Speed: 4.0ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 14.2ms\n",
            "Speed: 3.4ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 17.2ms\n",
            "Speed: 3.7ms preprocess, 17.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.3ms\n",
            "Speed: 6.5ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 18.2ms\n",
            "Speed: 5.4ms preprocess, 18.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 20.6ms\n",
            "Speed: 3.3ms preprocess, 20.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 14.4ms\n",
            "Speed: 3.6ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.8ms\n",
            "Speed: 3.7ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 24.8ms\n",
            "Speed: 3.0ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 2.9ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.7ms\n",
            "Speed: 10.0ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.0ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 17.6ms\n",
            "Speed: 3.1ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 14.8ms\n",
            "Speed: 5.7ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 21.2ms\n",
            "Speed: 5.8ms preprocess, 21.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 24.0ms\n",
            "Speed: 3.2ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 21.7ms\n",
            "Speed: 3.1ms preprocess, 21.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 4.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 15.3ms\n",
            "Speed: 5.6ms preprocess, 15.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 20.2ms\n",
            "Speed: 3.3ms preprocess, 20.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 13.5ms\n",
            "Speed: 3.1ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 16.6ms\n",
            "Speed: 3.4ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 16.0ms\n",
            "Speed: 4.3ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 25.5ms\n",
            "Speed: 5.7ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.5ms\n",
            "Speed: 3.4ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.7ms\n",
            "Speed: 3.6ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 18.9ms\n",
            "Speed: 3.0ms preprocess, 18.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 4.6ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.6ms\n",
            "Speed: 2.9ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 peanut, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 14.6ms\n",
            "Speed: 6.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.4ms\n",
            "Speed: 4.5ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 4.4ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.6ms\n",
            "Speed: 3.5ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "탐지 완료! 결과 영상 저장됨: /content/peanut_test_video_output.mp4\n"
          ]
        }
      ]
    }
  ]
}